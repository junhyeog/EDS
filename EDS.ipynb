{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dd6feba-45e3-4e3f-88c2-5726052cfd61",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# EDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d91921bf-aa91-43a0-9547-eb50009c19a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9930926f",
   "metadata": {
    "papermill": {
     "duration": 10.488332,
     "end_time": "2022-04-25T01:51:47.257230",
     "exception": false,
     "start_time": "2022-04-25T01:51:36.768898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install pytorch_msssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fddf0fb",
   "metadata": {
    "papermill": {
     "duration": 2.668241,
     "end_time": "2022-04-25T01:51:49.952980",
     "exception": false,
     "start_time": "2022-04-25T01:51:47.284739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import skimage\n",
    "import sklearn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from pytorch_msssim import MS_SSIM, SSIM\n",
    "from skimage import metrics\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import cuda, nn\n",
    "from torch.utils.data import ConcatDataset, DataLoader, TensorDataset, random_split\n",
    "from torchvision import models, transforms, utils\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "%pylab inline\n",
    "matplotlib.use(\"Agg\")  # prevent plt memory leak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56a4fa3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "papermill": {
     "duration": 0.030228,
     "end_time": "2022-04-25T01:51:50.015637",
     "exception": false,
     "start_time": "2022-04-25T01:51:49.985409",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MISC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3d8b61-729e-43e9-a22e-395b1cd0fa4b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### reproductibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0390be3",
   "metadata": {
    "papermill": {
     "duration": 0.043227,
     "end_time": "2022-04-25T01:51:50.088708",
     "exception": false,
     "start_time": "2022-04-25T01:51:50.045481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(random_seed: int = 0):\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "\n",
    "\n",
    "global SEED\n",
    "SEED = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb54b03-7f27-41b7-9d29-c2bf051fd0b4",
   "metadata": {},
   "source": [
    "### save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8260ab3-8030-45e8-8d9c-0e5f1e61c118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_weight(model, path: str, weight_file_name: str):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    torch.save(model.state_dict(), f\"{path}/{weight_file_name}\")\n",
    "    print(f\"[+] Saved {path}/{weight_file_name}\")\n",
    "\n",
    "\n",
    "def save_loss(losses, path: str, loss_file_name: str):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    with open(f\"{path}/{loss_file_name}\", \"w+\") as f:\n",
    "        for loss in losses:\n",
    "            f.write(\"%s\\n\" % loss)\n",
    "    print(f\"[+] Saved {path}/{loss_file_name}\")\n",
    "\n",
    "\n",
    "def save_pil_image(pil_image, path, name):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    pil_image.save(f\"{path}/{name}\")\n",
    "\n",
    "\n",
    "def save_merged_pil_image(pil_imgs, path, name, titles=None):\n",
    "    fontsize = 15\n",
    "    plt.figure(tight_layout=True)\n",
    "\n",
    "    for i, pil_img in enumerate(pil_imgs):\n",
    "        plt.subplot(1, len(pil_imgs), i + 1)\n",
    "        if titles:\n",
    "            plt.title(titles[i], fontsize=fontsize)\n",
    "        if pil_img.mode != \"RGB\":\n",
    "            plt.imshow(pil_img, cmap=\"gray\")\n",
    "        else:\n",
    "            plt.imshow(pil_img)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    plt.savefig(f\"{path}/{name}\", transparent=True, bbox_inches=\"tight\", pad_inches=0)\n",
    "    plt.close(\"all\")  # prevent plt memory leak\n",
    "    plt.clf()  # prevent plt memory leak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93006fb6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "papermill": {
     "duration": 0.03037,
     "end_time": "2022-04-25T01:51:50.152007",
     "exception": false,
     "start_time": "2022-04-25T01:51:50.121637",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af5c757",
   "metadata": {
    "papermill": {
     "duration": 0.027634,
     "end_time": "2022-04-25T01:51:50.209615",
     "exception": false,
     "start_time": "2022-04-25T01:51:50.181981",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CIFAR10\n",
    "- 50000 + 10000 = 60000\n",
    "- **=> 40000 + (10000+10000)**\n",
    "- train_size: 40000\n",
    "- test_size: 20000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28f12499",
   "metadata": {
    "papermill": {
     "duration": 0.14529,
     "end_time": "2022-04-25T01:51:50.383621",
     "exception": false,
     "start_time": "2022-04-25T01:51:50.238331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_cifar10_dataloader(batch_size):\n",
    "    set_seed(SEED)\n",
    "    root = \"data/cifar10\"\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Resize((64, 64))])\n",
    "    train_data = torchvision.datasets.CIFAR10(\n",
    "        root=root, train=True, transform=transform, download=True\n",
    "    )\n",
    "\n",
    "    test_data = torchvision.datasets.CIFAR10(\n",
    "        root=root, train=False, transform=transform, download=True\n",
    "    )\n",
    "\n",
    "    train_size = len(train_data)\n",
    "    test_size = len(test_data)\n",
    "\n",
    "    train_data, extra_test_data = random_split(train_data, [train_size - 10000, 10000],)\n",
    "    test_data = ConcatDataset((extra_test_data, test_data))\n",
    "\n",
    "    train_size = len(train_data)\n",
    "    test_size = len(test_data)\n",
    "    print(f\"[+] load cifar10: train_size = {train_size}, test_size = {test_size}\")\n",
    "\n",
    "    train_c_data, train_p_data = random_split(\n",
    "        train_data, [train_size // 2, train_size // 2]\n",
    "    )\n",
    "    test_c_data, test_p_data = random_split(test_data, [test_size // 2, test_size // 2])\n",
    "\n",
    "    train_c_loader = DataLoader(\n",
    "        dataset=train_c_data, batch_size=batch_size, shuffle=True, drop_last=False\n",
    "    )\n",
    "    train_p_loader = DataLoader(\n",
    "        dataset=train_p_data, batch_size=batch_size, shuffle=True, drop_last=False\n",
    "    )\n",
    "\n",
    "    test_c_loader = DataLoader(\n",
    "        dataset=test_c_data, batch_size=batch_size, shuffle=False, drop_last=False,\n",
    "    )\n",
    "    test_p_loader = DataLoader(\n",
    "        dataset=test_p_data, batch_size=batch_size, shuffle=False, drop_last=False,\n",
    "    )\n",
    "    return train_c_loader, train_p_loader, test_c_loader, test_p_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7af5c5d2-f6c4-4684-9892-7bc8c55efcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(TensorDataset):\n",
    "    def __init__(self, files):\n",
    "        self.transform = transforms.Compose(\n",
    "            [transforms.ToTensor(), transforms.Resize((64, 64)),]\n",
    "        )\n",
    "        self.files = files\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.files[index % len(self.files)])\n",
    "        if img.mode != \"RGB\":\n",
    "            img = img.convert(\"RGB\")\n",
    "        img = self.transform(img)\n",
    "        return img, self.files[index % len(self.files)].split(\"\\\\\")[-1].split(\".\")[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1004f643",
   "metadata": {
    "papermill": {
     "duration": 0.027832,
     "end_time": "2022-04-25T01:51:50.439605",
     "exception": false,
     "start_time": "2022-04-25T01:51:50.411773",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CelebA in Kaggle\n",
    "- train_size: 182598\n",
    "- test_size: 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "390b20b0",
   "metadata": {
    "papermill": {
     "duration": 0.04229,
     "end_time": "2022-04-25T01:51:50.509853",
     "exception": false,
     "start_time": "2022-04-25T01:51:50.467563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_celeba_dataloader(batch_size, full=False):\n",
    "    set_seed(SEED)\n",
    "    root = \"data/celeba-dataset/img_align_celeba/img_align_celeba\"\n",
    "\n",
    "    train_paths, test_paths = train_test_split(\n",
    "        sorted(glob.glob(root + \"/*.*\")), test_size=20000, random_state=0, shuffle=True\n",
    "    )\n",
    "\n",
    "    if not full:\n",
    "        train_paths = train_paths[:40001]  #! limit train size\n",
    "    train_size = len(train_paths)\n",
    "    test_size = len(test_paths)\n",
    "    if train_size % 2:\n",
    "        train_size -= 1\n",
    "        train_paths = train_paths[:-1]\n",
    "    print(f\"[+] load celeba: train_size = {train_size}, test_size = {test_size}\")\n",
    "\n",
    "    train_dataset = ImageDataset(train_paths)\n",
    "    test_dataset = ImageDataset(test_paths)\n",
    "\n",
    "    train_c_dataset, train_p_dataset = random_split(\n",
    "        train_dataset, [train_size // 2, train_size // 2]\n",
    "    )\n",
    "    test_c_dataset, test_p_dataset = random_split(\n",
    "        test_dataset, [test_size // 2, test_size // 2]\n",
    "    )\n",
    "\n",
    "    train_c_loader = DataLoader(\n",
    "        dataset=train_c_dataset, batch_size=batch_size, shuffle=True, drop_last=True\n",
    "    )\n",
    "    train_p_loader = DataLoader(\n",
    "        dataset=train_p_dataset, batch_size=batch_size, shuffle=True, drop_last=True\n",
    "    )\n",
    "    test_c_loader = DataLoader(\n",
    "        dataset=test_c_dataset, batch_size=batch_size, shuffle=False, drop_last=True\n",
    "    )\n",
    "    test_p_loader = DataLoader(\n",
    "        dataset=test_p_dataset, batch_size=batch_size, shuffle=False, drop_last=True\n",
    "    )\n",
    "\n",
    "    return train_c_loader, train_p_loader, test_c_loader, test_p_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b078cbc",
   "metadata": {
    "papermill": {
     "duration": 0.0277,
     "end_time": "2022-04-25T01:51:50.565009",
     "exception": false,
     "start_time": "2022-04-25T01:51:50.537309",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## ImageNet in Kaggle\n",
    "- train_size: 115000\n",
    "- test_size: 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "451074cf",
   "metadata": {
    "papermill": {
     "duration": 0.041272,
     "end_time": "2022-04-25T01:51:50.633752",
     "exception": false,
     "start_time": "2022-04-25T01:51:50.592480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_imagenet_dataloader(batch_size, full=False):\n",
    "    set_seed(SEED)\n",
    "    # ImageNet100 - A Sample of ImageNet Classes\n",
    "    root = \"data/imagenet100\"\n",
    "\n",
    "    train_paths, test_paths = train_test_split(\n",
    "        sorted(glob.glob(root + \"/*/*/*.*\")),\n",
    "        test_size=20000,\n",
    "        random_state=0,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    if not full:\n",
    "        train_paths = train_paths[:40001]  #! limit train size\n",
    "    train_size = len(train_paths)\n",
    "    test_size = len(test_paths)\n",
    "\n",
    "    if train_size % 2:\n",
    "        train_size -= 1\n",
    "        train_paths = train_paths[:-1]\n",
    "    print(f\"[+] load imagenet: train_size = {train_size}, test_size = {test_size}\")\n",
    "\n",
    "    train_dataset = ImageDataset(train_paths)\n",
    "    test_dataset = ImageDataset(test_paths)\n",
    "\n",
    "    train_c_dataset, train_p_dataset = random_split(\n",
    "        train_dataset, [train_size // 2, train_size // 2]\n",
    "    )\n",
    "    test_c_dataset, test_p_dataset = random_split(\n",
    "        test_dataset, [test_size // 2, test_size // 2]\n",
    "    )\n",
    "\n",
    "    train_c_loader = DataLoader(\n",
    "        dataset=train_c_dataset, batch_size=batch_size, shuffle=True, drop_last=True\n",
    "    )\n",
    "    train_p_loader = DataLoader(\n",
    "        dataset=train_p_dataset, batch_size=batch_size, shuffle=True, drop_last=True\n",
    "    )\n",
    "    test_c_loader = DataLoader(\n",
    "        dataset=test_c_dataset, batch_size=batch_size, shuffle=False, drop_last=True\n",
    "    )\n",
    "    test_p_loader = DataLoader(\n",
    "        dataset=test_p_dataset, batch_size=batch_size, shuffle=False, drop_last=True\n",
    "    )\n",
    "\n",
    "    return train_c_loader, train_p_loader, test_c_loader, test_p_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebf3a20",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "papermill": {
     "duration": 0.027746,
     "end_time": "2022-04-25T01:51:50.688636",
     "exception": false,
     "start_time": "2022-04-25T01:51:50.660890",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2616264c",
   "metadata": {
    "papermill": {
     "duration": 0.049947,
     "end_time": "2022-04-25T01:51:50.766149",
     "exception": false,
     "start_time": "2022-04-25T01:51:50.716202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EDS(nn.Module):\n",
    "    \"\"\"EDS model\n",
    "\n",
    "    Args:\n",
    "        (c, p): pair of cover image, payload image\n",
    "    Returns\n",
    "        e_o: encoder output\n",
    "        d_o: decoder output\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(EDS, self).__init__()\n",
    "        self.name = \"EDS\"\n",
    "        self.define_encoder()\n",
    "        self.define_decoder()\n",
    "        self.weight_init_xavier_uniform()\n",
    "\n",
    "    def weight_init_xavier_uniform(self):\n",
    "        for submodule in self.modules():\n",
    "            if isinstance(submodule, torch.nn.Conv2d):\n",
    "                torch.nn.init.xavier_uniform_(submodule.weight)\n",
    "                # submodule.bias.data.fill_(0.01)\n",
    "\n",
    "    def make_seq(self, in_channels=16, out_channels=16, kernel_size=3, padding=1):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def define_decoder(self):\n",
    "        self.decoder = nn.ModuleList()\n",
    "        self.decoder.append(self.make_seq(in_channels=3))\n",
    "        self.decoder.append(self.make_seq())\n",
    "        self.decoder.append(self.make_seq(out_channels=8))\n",
    "        self.decoder.append(self.make_seq(in_channels=8, out_channels=8))\n",
    "        self.decoder.append(self.make_seq(in_channels=8, out_channels=3))\n",
    "        self.decoder.append(self.make_seq(in_channels=3, out_channels=3))\n",
    "        self.decoder.append(nn.Conv2d(3, 1, kernel_size=1))\n",
    "\n",
    "    def define_encoder(self):\n",
    "        # host branch\n",
    "        self.host_branch = nn.ModuleList()\n",
    "        self.host_branch.append(self.make_seq(3))\n",
    "        self.host_branch.append(self.make_seq(in_channels=32))\n",
    "        self.host_branch.append(self.make_seq())\n",
    "        self.host_branch.append(self.make_seq(in_channels=32))\n",
    "        self.host_branch.append(self.make_seq())\n",
    "        self.host_branch.append(self.make_seq(in_channels=32))\n",
    "        self.host_branch.append(self.make_seq())\n",
    "        self.host_branch.append(self.make_seq(in_channels=32, kernel_size=1, padding=0))\n",
    "        self.host_branch.append(self.make_seq(out_channels=8, kernel_size=1, padding=0))\n",
    "        self.host_branch.append(nn.Conv2d(8, 3, kernel_size=1, padding=0))\n",
    "\n",
    "        # guest branch\n",
    "        self.guest_branch = nn.ModuleList()\n",
    "        self.guest_branch.append(self.make_seq(1))\n",
    "        for i in range(6):\n",
    "            self.guest_branch.append(self.make_seq())\n",
    "\n",
    "    def forward(self, c, p):\n",
    "        ##### Encoder #####\n",
    "        # layer1\n",
    "        p1 = self.guest_branch[0](p)\n",
    "        c1 = self.host_branch[0](c)\n",
    "        c1_p1 = torch.cat((c1, p1), 1)  # 32 channels\n",
    "        # layer2\n",
    "        p2 = self.guest_branch[1](p1)\n",
    "        c2 = self.host_branch[1](c1_p1)\n",
    "        # layer3\n",
    "        p3 = self.guest_branch[2](p2)\n",
    "        c3 = self.host_branch[2](c2)\n",
    "        c3_p3 = torch.cat((c3, p3), 1)  # 32 channels\n",
    "        # layer4\n",
    "        p4 = self.guest_branch[3](p3)\n",
    "        c4 = self.host_branch[3](c3_p3)\n",
    "        # layer5\n",
    "        p5 = self.guest_branch[4](p4)\n",
    "        c5 = self.host_branch[4](c4)\n",
    "        c5_p5 = torch.cat((c5, p5), 1)  # 32 channels\n",
    "        # layer6\n",
    "        p6 = self.guest_branch[5](p5)\n",
    "        c6 = self.host_branch[5](c5_p5)\n",
    "        # layer7\n",
    "        p7 = self.guest_branch[6](p6)\n",
    "        c7 = self.host_branch[6](c6)\n",
    "        c7_p7 = torch.cat((c7, p7), 1)  # 32 channels\n",
    "        # layer8\n",
    "        c8 = self.host_branch[7](c7_p7)\n",
    "        # layer9\n",
    "        c9 = self.host_branch[8](c8)\n",
    "        # layer10\n",
    "        encoder_output = self.host_branch[9](c9)\n",
    "\n",
    "        ##### Decoder #####\n",
    "        decoder_output = encoder_output\n",
    "        for layer in self.decoder:\n",
    "            decoder_output = layer(decoder_output)\n",
    "\n",
    "        return encoder_output, decoder_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce95a9e2-236d-4fb4-bc83-3084351c1bbc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c33af1e9-dfae-4ee5-8719-94bf59cddd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For L2 regularization\n",
    "# Instead of this, we can use weight_decay in optimizer\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "def get_MSE_from_moduleList(moduleList):\n",
    "    device = \"cuda\" if cuda.is_available() else \"cpu\"\n",
    "    w = torch.tensor(0, dtype=torch.get_default_dtype()).to(device)\n",
    "    cnt = 0\n",
    "    for layer in moduleList:\n",
    "        for params in layer.parameters():\n",
    "            w.add_(torch.mean(torch.square(params)))\n",
    "            cnt += params.nelement()\n",
    "    return w / cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ca24245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(coefficients, c, p, e_out, d_out):\n",
    "    \"\"\"get_loss function\n",
    "\n",
    "    Args:\n",
    "        model (model): EDS model\n",
    "        criterion (criterion): MSELoss\n",
    "        coefficients (dict): {alpha, beta, lambd}\n",
    "        c (B 3 W H): cover image batch\n",
    "        p (B 1 W H): payload image batch\n",
    "        e_out (B 3 W H): encoded(stego) image batch\n",
    "        d_out (B 1 W H): decoded image batch\n",
    "\n",
    "    Returns:\n",
    "        loss\n",
    "    \"\"\"\n",
    "    e_loss = nn.MSELoss()(c, e_out)\n",
    "    d_loss = nn.MSELoss()(p, d_out)\n",
    "    # Instead of get_MSE_from_moduleList, using weight_decay\n",
    "    #     w_d = get_MSE_from_moduleList(model.decoder)\n",
    "    #     w_h = get_MSE_from_moduleList(model.host_branch)\n",
    "    #     w_g = get_MSE_from_moduleList(model.guest_branch)\n",
    "    #     w_loss = (w_h + w_g) / 2 + w_d\n",
    "\n",
    "    #     loss = (\n",
    "    #         coefficients[\"alpha\"] * e_loss\n",
    "    #         + coefficients[\"beta\"] * d_loss\n",
    "    #         + coefficients[\"lambd\"] * w_loss\n",
    "    #     )\n",
    "    loss = coefficients[\"alpha\"] * e_loss + coefficients[\"beta\"] * d_loss\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de0b648",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "papermill": {
     "duration": 0.027122,
     "end_time": "2022-04-25T01:51:50.938266",
     "exception": false,
     "start_time": "2022-04-25T01:51:50.911144",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d54551f1",
   "metadata": {
    "papermill": {
     "duration": 0.039802,
     "end_time": "2022-04-25T01:51:51.194815",
     "exception": false,
     "start_time": "2022-04-25T01:51:51.155013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_save(\n",
    "    model,\n",
    "    optimizer,\n",
    "    train_c_dataloader,\n",
    "    train_p_dataloader,\n",
    "    epochs,\n",
    "    period,\n",
    "    coefficients,\n",
    "    weight_path,\n",
    "):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    batchs = min(len(train_c_dataloader), len(train_p_dataloader))\n",
    "\n",
    "    for epoch in trange(1, epochs + 1, desc=\"Total\"):\n",
    "        loss_item = 0.0\n",
    "        iter_c = iter(train_c_dataloader)\n",
    "        iter_p = iter(train_p_dataloader)\n",
    "        # pbar = tqdm(range(batchs), desc=f\"Epoch {epoch}/{epochs}\", ascii=True, leave=False)\n",
    "        pbar = range(batchs)\n",
    "        for i in pbar:\n",
    "            c = next(iter_c)[0].to(device)\n",
    "            p = next(iter_p)[0].to(device)\n",
    "            p = transforms.functional.rgb_to_grayscale(\n",
    "                p\n",
    "            )  # (B, 1, H, W) # to_pil_image했을 때 제대로 나오는거 확인 O\n",
    "\n",
    "            ### train step\n",
    "            optimizer.zero_grad()\n",
    "            e_out, d_out = model.forward(c, p)\n",
    "            loss = get_loss(coefficients, c, p, e_out, d_out)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_item += loss.item()\n",
    "\n",
    "        losses.append(loss_item / batchs)\n",
    "        # print(f\"[+] Train loss({epoch}/{epochs}): {train_losses[-1]}\")\n",
    "        # checkpoint\n",
    "        if epoch % period == 0 and len(weight_path) and epoch:\n",
    "            save_weight(model, weight_path, f\"{epoch}.pickle\")\n",
    "            save_loss(losses, weight_path, f\"{epoch}.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9142ec2a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "papermill": {
     "duration": 0.027878,
     "end_time": "2022-04-25T01:51:51.249983",
     "exception": false,
     "start_time": "2022-04-25T01:51:51.222105",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Test (Infer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6c13a91",
   "metadata": {
    "papermill": {
     "duration": 0.045823,
     "end_time": "2022-04-25T01:51:51.451164",
     "exception": false,
     "start_time": "2022-04-25T01:51:51.405341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def infer_from_saved_weight(\n",
    "    model, test_c_dataloader, test_p_dataloader, weight_file, result_path\n",
    "):\n",
    "    with torch.no_grad():\n",
    "        model.load_state_dict(torch.load(weight_file, map_location=device))\n",
    "        model.eval()\n",
    "\n",
    "        batchs = min(len(test_c_dataloader), len(test_p_dataloader))\n",
    "        len_datas = min(len(test_c_dataloader.dataset), len(test_p_dataloader.dataset))\n",
    "\n",
    "        iter_c = iter(test_c_dataloader)\n",
    "        iter_p = iter(test_p_dataloader)\n",
    "        total_e_psnr = 0.0\n",
    "        total_d_psnr = 0.0\n",
    "        total_e_ssim = 0.0\n",
    "        total_d_ssim = 0.0\n",
    "        total_e = 0\n",
    "        total_d = 0\n",
    "        for batch in trange(batchs, desc=\"Total\"):\n",
    "            # for batch in range(batchs):\n",
    "            e_psnr = 0.0\n",
    "            e_cnt = 0\n",
    "            d_psnr = 0.0\n",
    "            d_cnt = 0\n",
    "            e_ssim = 0.0\n",
    "            d_ssim = 0.0\n",
    "            c = next(iter_c)[0].to(device)\n",
    "            p = next(iter_p)[0].to(device)\n",
    "            p = transforms.functional.rgb_to_grayscale(\n",
    "                p\n",
    "            )  # to_pil_image했을 때 제대로 나오는거 확인 O\n",
    "            e_o, d_o = model(c, p)  # infer\n",
    "            pbar = range(c.shape[0])\n",
    "            for i in pbar:\n",
    "                c_np = (\n",
    "                    c[i]\n",
    "                    .mul(255)\n",
    "                    .add_(0.5)\n",
    "                    .clamp_(0, 255)\n",
    "                    .permute(1, 2, 0)\n",
    "                    .to(\"cpu\", torch.uint8)\n",
    "                    .numpy()\n",
    "                )\n",
    "                p_np = (\n",
    "                    p[i]\n",
    "                    .mul(255)\n",
    "                    .add_(0.5)\n",
    "                    .clamp_(0, 255)\n",
    "                    .permute(1, 2, 0)\n",
    "                    .to(\"cpu\", torch.uint8)\n",
    "                    .numpy()\n",
    "                    .squeeze()\n",
    "                )\n",
    "                e_o_np = (\n",
    "                    e_o[i]\n",
    "                    .mul(255)\n",
    "                    .add_(0.5)\n",
    "                    .clamp_(0, 255)\n",
    "                    .permute(1, 2, 0)\n",
    "                    .to(\"cpu\", torch.uint8)\n",
    "                    .numpy()\n",
    "                )\n",
    "                d_o_np = (\n",
    "                    d_o[i]\n",
    "                    .mul(255)\n",
    "                    .add_(0.5)\n",
    "                    .clamp_(0, 255)\n",
    "                    .permute(1, 2, 0)\n",
    "                    .to(\"cpu\", torch.uint8)\n",
    "                    .numpy()\n",
    "                    .squeeze()\n",
    "                )\n",
    "                c_img = Image.fromarray(c_np)\n",
    "                p_img = Image.fromarray(p_np)\n",
    "                e_o_img = Image.fromarray(e_o_np)\n",
    "                d_o_img = Image.fromarray(d_o_np)\n",
    "                # save result images\n",
    "                save_merged_pil_image(\n",
    "                    [c_img, p_img, e_o_img, d_o_img],\n",
    "                    f\"{result_path}/merged\",\n",
    "                    f\"{batch}-{i}.png\",\n",
    "                )  ## merged image\n",
    "                ## c, p, e_o, d_o separately\n",
    "                save_pil_image(c_img, f\"{result_path}/c\", f\"{batch}-{i}.png\")\n",
    "                # save_pil_image(p_img, f\"{result_path}/p\", f\"{batch}-{i}.png\")\n",
    "                # save_pil_image(d_o_img, f\"{result_path}/d_o\", f\"{batch}-{i}.png\")\n",
    "                save_pil_image(\n",
    "                    e_o_img, f\"{result_path}/e_o\", f\"{batch}-{i}.png\"\n",
    "                )  # encoded cover (stego) image\n",
    "\n",
    "                # calc psnr, ssim\n",
    "                psnr = skimage.metrics.peak_signal_noise_ratio(c_np, e_o_np)\n",
    "                if psnr != np.inf:\n",
    "                    e_psnr += psnr\n",
    "                    e_cnt += 1\n",
    "                psnr = skimage.metrics.peak_signal_noise_ratio(p_np, d_o_np)\n",
    "                if psnr != np.inf:\n",
    "                    d_psnr += psnr\n",
    "                    d_cnt += 1\n",
    "                e_ssim += skimage.metrics.structural_similarity(\n",
    "                    c_np,\n",
    "                    e_o_np,\n",
    "                    multichannel=True,\n",
    "                    channel_axis=2,  # channel 3개로 나눠서 계산한 평균과 같은 값이 나옴\n",
    "                )\n",
    "                d_ssim += skimage.metrics.structural_similarity(p_np, d_o_np)\n",
    "            total_e += e_cnt\n",
    "            total_d += d_cnt\n",
    "            # save psnr, ssim\n",
    "            with open(f\"{result_path}/metrics-per-batch.txt\", \"a+\") as f:\n",
    "                f.write(f\"# {batch}\\n\")\n",
    "                f.write(f\"e_psnr: {e_psnr/e_cnt}\\n\")\n",
    "                f.write(f\"d_psnr: {d_psnr/d_cnt}\\n\")\n",
    "                f.write(f\"e_ssim: {e_ssim/batch_size}\\n\")\n",
    "                f.write(f\"d_ssim: {d_ssim/batch_size}\\n\")\n",
    "            total_e_psnr += e_psnr\n",
    "            total_d_psnr += d_psnr\n",
    "            total_e_ssim += e_ssim\n",
    "            total_d_ssim += d_ssim\n",
    "        with open(result_path + \"/metrics-total.txt\", \"w+\") as f:\n",
    "            f.write(f\"total_e_psnr: {total_e_psnr/total_e}\\n\")\n",
    "            f.write(f\"total_d_psnr: {total_d_psnr/total_d}\\n\")\n",
    "            f.write(f\"total_e_ssim: {total_e_ssim/len_datas}\\n\")\n",
    "            f.write(f\"total_d_ssim: {total_d_ssim/len_datas}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947cbcef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "papermill": {
     "duration": 0.026976,
     "end_time": "2022-04-25T01:51:51.505223",
     "exception": false,
     "start_time": "2022-04-25T01:51:51.478247",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ae7e85",
   "metadata": {
    "papermill": {
     "duration": 0.026954,
     "end_time": "2022-04-25T01:51:51.559677",
     "exception": false,
     "start_time": "2022-04-25T01:51:51.532723",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- weight/{model.name}/{train_set}/{epoch}.pickle\n",
    "    - cifar10\n",
    "        - 50.pickle\n",
    "        - 100.pickle\n",
    "        - 150.pickle\n",
    "    - celeba\n",
    "        - 50.pickle\n",
    "        - 100.pickle\n",
    "        - 150.pickle\n",
    "    - imagenet\n",
    "        - 50.pickle\n",
    "        - 100.pickle\n",
    "        - 150.pickle\n",
    "- result/{model.name}/{train_set}/{test_set}/{epoch}/{[c, p, d_o, e_d]}/*.png\n",
    "    - cifar10\n",
    "        - cifar10\n",
    "            - 150\n",
    "                - c\n",
    "                - e_o\n",
    "                - merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dbc205",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "papermill": {
     "duration": 0.029932,
     "end_time": "2022-04-25T01:51:51.789246",
     "exception": false,
     "start_time": "2022-04-25T01:51:51.759314",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train and infer with dataset (CIFAR10, CelebA, ImageNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "268698df",
   "metadata": {
    "papermill": {
     "duration": 0.03714,
     "end_time": "2022-04-25T01:51:51.853841",
     "exception": false,
     "start_time": "2022-04-25T01:51:51.816701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(train_set):\n",
    "    # train loader\n",
    "    if train_set == \"cifar10\":\n",
    "        train_c_dataloader, train_p_dataloader = build_cifar10_dataloader(batch_size)[\n",
    "            :2\n",
    "        ]\n",
    "    elif train_set == \"celeba\":\n",
    "        train_c_dataloader, train_p_dataloader = build_celeba_dataloader(batch_size)[:2]\n",
    "    elif train_set == \"imagenet\":\n",
    "        train_c_dataloader, train_p_dataloader = build_imagenet_dataloader(batch_size)[\n",
    "            :2\n",
    "        ]\n",
    "    else:\n",
    "        print(\"[-] invalid train_set\")\n",
    "        return\n",
    "\n",
    "    model = EDS().to(device)  ###############\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=lambd)\n",
    "    weight_path = f\"./weight/{model.name}/{train_set}\"\n",
    "\n",
    "    train_and_save(\n",
    "        model,\n",
    "        optimizer,\n",
    "        train_c_dataloader,\n",
    "        train_p_dataloader,\n",
    "        epochs,\n",
    "        period,\n",
    "        coefficients,\n",
    "        weight_path,\n",
    "    )\n",
    "    del train_c_dataloader, train_p_dataloader, model\n",
    "    print(f\"[+] train {train_set} done (epochs: {epochs})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "026b65c6",
   "metadata": {
    "papermill": {
     "duration": 0.036946,
     "end_time": "2022-04-25T01:51:51.974382",
     "exception": false,
     "start_time": "2022-04-25T01:51:51.937436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def infer(train_set, infer_set):\n",
    "    # test loader\n",
    "    if infer_set == \"cifar10\":\n",
    "        test_c_dataloader, test_p_dataloader = build_cifar10_dataloader(batch_size)[2:]\n",
    "    elif infer_set == \"celeba\":\n",
    "        test_c_dataloader, test_p_dataloader = build_celeba_dataloader(batch_size)[2:]\n",
    "    elif infer_set == \"imagenet\":\n",
    "        test_c_dataloader, test_p_dataloader = build_imagenet_dataloader(batch_size)[2:]\n",
    "    else:\n",
    "        print(\"[-] invalid test_set\")\n",
    "        return\n",
    "\n",
    "    model = EDS().to(device)  ###############\n",
    "    weight_path = f\"./weight/{model.name}/{train_set}\"\n",
    "    for e in range(epochs, 0, -period):\n",
    "        result_path = f\"./result/{model.name}/{train_set}/{infer_set}/{e}\"\n",
    "        infer_from_saved_weight(\n",
    "            model,\n",
    "            test_c_dataloader,\n",
    "            test_p_dataloader,\n",
    "            f\"{weight_path}/{e}.pickle\",\n",
    "            result_path,\n",
    "        )\n",
    "        # shutil.make_archive(\n",
    "        #     f\"{model.name}-{train_set}-{infer_set}-{e}\", \"zip\", result_path\n",
    "        # )\n",
    "        print(f\"[+] infer {infer_set} with {model.name}-{train_set} (epochs: {e}) done\")\n",
    "    del test_c_dataloader, test_p_dataloader, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38bdded4",
   "metadata": {
    "papermill": {
     "duration": 0.034729,
     "end_time": "2022-04-25T01:51:52.036415",
     "exception": false,
     "start_time": "2022-04-25T01:51:52.001686",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_infer():\n",
    "    for train_set in datasets:\n",
    "        train(train_set)\n",
    "        for infer_set in datasets:\n",
    "            infer(train_set, infer_set)\n",
    "    print(\"[+] weight saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe771992-e0c8-4902-823b-441097cd9bec",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Global variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f44d169",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2022-04-25T01:51:52.063797",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "global device, batch_size, epochs, period, lr, coeddicients, lambd, datasets\n",
    "\n",
    "device = \"cuda\" if cuda.is_available() else \"cpu\"\n",
    "batch_size = 32\n",
    "epochs = 150\n",
    "period = 50\n",
    "lr = 1e-4\n",
    "lambd = 1e-4\n",
    "coefficients = {\n",
    "    \"alpha\": 1,\n",
    "    \"beta\": 1,\n",
    "}\n",
    "\n",
    "datasets = [\"cifar10\", \"celeba\", \"imagenet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605f32e8-e9ec-4771-aa38-869f6169a7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Device: cuda\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[+] load cifar10: train_size = 40000, test_size = 20000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d8bb4831f71480389e5d59489691635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run\n",
    "print(\"[+] Device:\", device)\n",
    "train_and_infer()\n",
    "print(\"[+] done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-jhyun",
   "language": "python",
   "name": "pytorch-jhyun"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-25T01:51:28.844418",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
