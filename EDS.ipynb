{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dd6feba-45e3-4e3f-88c2-5726052cfd61",
   "metadata": {
    "tags": []
   },
   "source": [
    "# EDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fddf0fb",
   "metadata": {
    "papermill": {
     "duration": 2.668241,
     "end_time": "2022-04-25T01:51:49.952980",
     "exception": false,
     "start_time": "2022-04-25T01:51:47.284739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, cuda\n",
    "from tqdm.auto import trange, tqdm\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split, ConcatDataset\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import skimage\n",
    "from skimage import metrics\n",
    "import os\n",
    "import sklearn\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from pytorch_msssim import SSIM, MS_SSIM\n",
    "import shutil\n",
    "\n",
    "%pylab inline\n",
    "matplotlib.use('Agg') # prevent plt memory leak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56a4fa3",
   "metadata": {
    "papermill": {
     "duration": 0.030228,
     "end_time": "2022-04-25T01:51:50.015637",
     "exception": false,
     "start_time": "2022-04-25T01:51:49.985409",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# For reproductibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0390be3",
   "metadata": {
    "papermill": {
     "duration": 0.043227,
     "end_time": "2022-04-25T01:51:50.088708",
     "exception": false,
     "start_time": "2022-04-25T01:51:50.045481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_seed=0\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93006fb6",
   "metadata": {
    "papermill": {
     "duration": 0.03037,
     "end_time": "2022-04-25T01:51:50.152007",
     "exception": false,
     "start_time": "2022-04-25T01:51:50.121637",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af5c757",
   "metadata": {
    "papermill": {
     "duration": 0.027634,
     "end_time": "2022-04-25T01:51:50.209615",
     "exception": false,
     "start_time": "2022-04-25T01:51:50.181981",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CIFAR10\n",
    "- 50000 + 10000 = 60000\n",
    "- **=> 40000 + (10000+10000)**\n",
    "- train_size: 40000\n",
    "- test_size: 20000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28f12499",
   "metadata": {
    "papermill": {
     "duration": 0.14529,
     "end_time": "2022-04-25T01:51:50.383621",
     "exception": false,
     "start_time": "2022-04-25T01:51:50.238331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_cifar10_dataloader(batch_size):\n",
    "    root='data/cifar10'\n",
    "    train_transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((64, 64)),\n",
    "            # transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    test_transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((64, 64)),\n",
    "            # transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    train_data = datasets.CIFAR10(\n",
    "        root=root, train=True, transform=train_transform, download=True\n",
    "    )\n",
    "    test_data = datasets.CIFAR10(\n",
    "        root=root, train=False, transform=test_transform, download=True\n",
    "    )\n",
    "\n",
    "    train_size = len(train_data)\n",
    "    test_size = len(test_data)\n",
    "\n",
    "    train_data, extra_test_data = random_split(\n",
    "        train_data, [train_size-10000, 10000], generator=torch.Generator().manual_seed(0)\n",
    "    )\n",
    "    test_data=ConcatDataset((extra_test_data, test_data))\n",
    "\n",
    "    train_size = len(train_data)\n",
    "    test_size = len(test_data)\n",
    "    print(f\"[+] load cifar10: train_size = {train_size}, test_size = {test_size}\")\n",
    "\n",
    "    train_c_data, train_p_data = random_split(train_data, [train_size//2, train_size//2])\n",
    "    test_c_data, test_p_data = random_split(test_data, [test_size//2, test_size//2])\n",
    "\n",
    "    train_c_loader = DataLoader(\n",
    "        dataset=train_c_data, batch_size=batch_size, shuffle=True, drop_last=True\n",
    "    )\n",
    "    train_p_loader = DataLoader(\n",
    "        dataset=train_p_data, batch_size=batch_size, shuffle=True, drop_last=True\n",
    "    )\n",
    "\n",
    "    test_c_loader = DataLoader(\n",
    "        dataset=test_c_data, batch_size=batch_size, shuffle=False, drop_last=True\n",
    "    )\n",
    "    test_p_loader = DataLoader(\n",
    "        dataset=test_p_data, batch_size=batch_size, shuffle=False, drop_last=True\n",
    "    )\n",
    "    return train_c_loader, train_p_loader, test_c_loader, test_p_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1004f643",
   "metadata": {
    "papermill": {
     "duration": 0.027832,
     "end_time": "2022-04-25T01:51:50.439605",
     "exception": false,
     "start_time": "2022-04-25T01:51:50.411773",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CelebA in Kaggle\n",
    "- train_size: 182598\n",
    "- test_size: 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "390b20b0",
   "metadata": {
    "papermill": {
     "duration": 0.04229,
     "end_time": "2022-04-25T01:51:50.509853",
     "exception": false,
     "start_time": "2022-04-25T01:51:50.467563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_celeba_dataloader(batch_size, full=False):\n",
    "    root = \"data/celeba-dataset/img_align_celeba/img_align_celeba\"\n",
    "    class ImageDataset(TensorDataset):\n",
    "        def __init__(self, files):\n",
    "            self.transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Resize((64, 64)),\n",
    "                    # transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "                ]\n",
    "            )\n",
    "            self.files = files\n",
    "        def __getitem__(self, index):\n",
    "            img = Image.open(self.files[index % len(self.files)])\n",
    "            img=self.transform(img)\n",
    "            return img, 0\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.files)\n",
    "\n",
    "    import glob\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_paths, test_paths = train_test_split(sorted(glob.glob(root + \"/*.*\")), test_size=20000, random_state=0, shuffle=True)\n",
    "    \n",
    "    if not full:\n",
    "        train_paths=train_paths[:40001] #! limit train size\n",
    "    train_size=len(train_paths)\n",
    "    test_size=len(test_paths)\n",
    "    if train_size % 2:\n",
    "        train_size -= 1\n",
    "        train_paths = train_paths[:-1]\n",
    "    print(f\"[+] load celeba: train_size = {train_size}, test_size = {test_size}\")\n",
    "    \n",
    "    train_dataset=ImageDataset(train_paths)\n",
    "    test_dataset=ImageDataset(test_paths)\n",
    "    \n",
    "    train_c_dataset, train_p_dataset = random_split(train_dataset, [train_size // 2, train_size // 2])\n",
    "    test_c_dataset, test_p_dataset = random_split(test_dataset, [test_size // 2, test_size // 2])\n",
    "\n",
    "    train_c_loader = DataLoader(\n",
    "        dataset=train_c_dataset, batch_size=batch_size, shuffle=True, drop_last=True\n",
    "    )\n",
    "    train_p_loader = DataLoader(\n",
    "        dataset=train_p_dataset, batch_size=batch_size, shuffle=True, drop_last=True\n",
    "    )\n",
    "    test_c_loader = DataLoader(\n",
    "        dataset=test_c_dataset, batch_size=batch_size, shuffle=False, drop_last=True\n",
    "    )\n",
    "    test_p_loader = DataLoader(\n",
    "        dataset=test_p_dataset, batch_size=batch_size, shuffle=False, drop_last=True\n",
    "    )\n",
    "\n",
    "    return train_c_loader, train_p_loader, test_c_loader, test_p_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b078cbc",
   "metadata": {
    "papermill": {
     "duration": 0.0277,
     "end_time": "2022-04-25T01:51:50.565009",
     "exception": false,
     "start_time": "2022-04-25T01:51:50.537309",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## ImageNet in Kaggle\n",
    "- train_size: 115000\n",
    "- test_size: 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "451074cf",
   "metadata": {
    "papermill": {
     "duration": 0.041272,
     "end_time": "2022-04-25T01:51:50.633752",
     "exception": false,
     "start_time": "2022-04-25T01:51:50.592480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_imagenet_dataloader(batch_size, full=False):\n",
    "    # ImageNet100 - A Sample of ImageNet Classes\n",
    "    root = \"data/imagenet100\"\n",
    "    class ImageDataset(TensorDataset):\n",
    "        def __init__(self, files):\n",
    "            self.transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Resize((64, 64)),\n",
    "                    # transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "                ]\n",
    "            )\n",
    "            self.files = files\n",
    "        def __getitem__(self, index):\n",
    "            img = Image.open(self.files[index % len(self.files)])\n",
    "            if img.mode!='RGB':\n",
    "                img = img.convert('RGB')\n",
    "            img=self.transform(img)\n",
    "            return img, 0\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.files)\n",
    "\n",
    "    import glob\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_paths, test_paths = train_test_split(sorted(glob.glob(root + \"/*/*/*.*\")), test_size=20000, random_state=0, shuffle=True)\n",
    "    \n",
    "    if not full:\n",
    "        train_paths=train_paths[:40001] #! limit train size\n",
    "    train_size=len(train_paths)\n",
    "    test_size=len(test_paths)\n",
    "    \n",
    "    if train_size % 2:\n",
    "        train_size -= 1\n",
    "        train_paths = train_paths[:-1]\n",
    "    print(f\"[+] load imagenet: train_size = {train_size}, test_size = {test_size}\")\n",
    "    \n",
    "    train_dataset=ImageDataset(train_paths)\n",
    "    test_dataset=ImageDataset(test_paths)\n",
    "    \n",
    "    train_c_dataset, train_p_dataset = random_split(train_dataset, [train_size // 2, train_size // 2])\n",
    "    test_c_dataset, test_p_dataset = random_split(test_dataset, [test_size // 2, test_size // 2])\n",
    "\n",
    "    train_c_loader = DataLoader(\n",
    "        dataset=train_c_dataset, batch_size=batch_size, shuffle=True, drop_last=True\n",
    "    )\n",
    "    train_p_loader = DataLoader(\n",
    "        dataset=train_p_dataset, batch_size=batch_size, shuffle=True, drop_last=True\n",
    "    )\n",
    "    test_c_loader = DataLoader(\n",
    "        dataset=test_c_dataset, batch_size=batch_size, shuffle=False, drop_last=True\n",
    "    )\n",
    "    test_p_loader = DataLoader(\n",
    "        dataset=test_p_dataset, batch_size=batch_size, shuffle=False, drop_last=True\n",
    "    )\n",
    "\n",
    "    return train_c_loader, train_p_loader, test_c_loader, test_p_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebf3a20",
   "metadata": {
    "papermill": {
     "duration": 0.027746,
     "end_time": "2022-04-25T01:51:50.688636",
     "exception": false,
     "start_time": "2022-04-25T01:51:50.660890",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2616264c",
   "metadata": {
    "papermill": {
     "duration": 0.049947,
     "end_time": "2022-04-25T01:51:50.766149",
     "exception": false,
     "start_time": "2022-04-25T01:51:50.716202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EDS(nn.Module):\n",
    "    \"\"\"EDS model\n",
    "\n",
    "    Args:\n",
    "        (c, p): pair of cover image, payload image\n",
    "    Returns\n",
    "        e_o: encoder output\n",
    "        d_o: decoder output\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(EDS, self).__init__()\n",
    "        self.name=\"EDS\"\n",
    "        self.define_encoder()\n",
    "        self.define_decoder()\n",
    "\n",
    "    def make_seq(self, in_channels=16, out_channels=16, kernel_size=3, padding=1):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def define_decoder(self):\n",
    "        self.decoder = nn.ModuleList()\n",
    "        self.decoder.append(self.make_seq(in_channels=3))\n",
    "        self.decoder.append(self.make_seq())\n",
    "        self.decoder.append(self.make_seq(out_channels=8))\n",
    "        self.decoder.append(self.make_seq(in_channels=8, out_channels=8))\n",
    "        self.decoder.append(self.make_seq(in_channels=8, out_channels=3))\n",
    "        self.decoder.append(self.make_seq(in_channels=3, out_channels=3))\n",
    "        self.decoder.append(nn.Conv2d(3, 1, kernel_size=1))\n",
    "\n",
    "    def define_encoder(self):\n",
    "        # host branch\n",
    "        self.host_branch = nn.ModuleList()\n",
    "        self.host_branch.append(self.make_seq(3))\n",
    "        self.host_branch.append(self.make_seq(in_channels=32))\n",
    "        self.host_branch.append(self.make_seq())\n",
    "        self.host_branch.append(self.make_seq(in_channels=32))\n",
    "        self.host_branch.append(self.make_seq())\n",
    "        self.host_branch.append(self.make_seq(in_channels=32))\n",
    "        self.host_branch.append(self.make_seq())\n",
    "        self.host_branch.append(self.make_seq(in_channels=32, kernel_size=1, padding=0))\n",
    "        self.host_branch.append(self.make_seq(out_channels=8, kernel_size=1, padding=0))\n",
    "        self.host_branch.append(nn.Conv2d(8, 3, kernel_size=1, padding=0))\n",
    "\n",
    "        # guest branch\n",
    "        self.guest_branch = nn.ModuleList()\n",
    "        self.guest_branch.append(self.make_seq(1))\n",
    "        for i in range(6):\n",
    "            self.guest_branch.append(self.make_seq())\n",
    "\n",
    "    def forward(self, c, p):\n",
    "        ##### Encoder #####\n",
    "        # layer1\n",
    "        p1 = self.guest_branch[0](p)\n",
    "        c1 = self.host_branch[0](c)\n",
    "        c1_p1 = torch.cat((c1, p1), 1)  # 32 channels\n",
    "        # layer2\n",
    "        p2 = self.guest_branch[1](p1)\n",
    "        c2 = self.host_branch[1](c1_p1)\n",
    "        # layer3\n",
    "        p3 = self.guest_branch[2](p2)\n",
    "        c3 = self.host_branch[2](c2)\n",
    "        c3_p3 = torch.cat((c3, p3), 1)  # 32 channels\n",
    "        # layer4\n",
    "        p4 = self.guest_branch[3](p3)\n",
    "        c4 = self.host_branch[3](c3_p3)\n",
    "        # layer5\n",
    "        p5 = self.guest_branch[4](p4)\n",
    "        c5 = self.host_branch[4](c4)\n",
    "        c5_p5 = torch.cat((c5, p5), 1)  # 32 channels\n",
    "        # layer6\n",
    "        p6 = self.guest_branch[5](p5)\n",
    "        c6 = self.host_branch[5](c5_p5)\n",
    "        # layer7\n",
    "        p7 = self.guest_branch[6](p6)\n",
    "        c7 = self.host_branch[6](c6)\n",
    "        c7_p7 = torch.cat((c7, p7), 1)  # 32 channels\n",
    "        # layer8\n",
    "        c8 = self.host_branch[7](c7_p7)\n",
    "        # layer9\n",
    "        c9 = self.host_branch[8](c8)\n",
    "        # layer10\n",
    "        encoder_output = self.host_branch[9](c9)\n",
    "\n",
    "        ##### Decoder #####\n",
    "        decoder_output = encoder_output\n",
    "        for layer in self.decoder:\n",
    "            decoder_output = layer(decoder_output)\n",
    "\n",
    "        return encoder_output, decoder_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ba9338",
   "metadata": {
    "papermill": {
     "duration": 0.027399,
     "end_time": "2022-04-25T01:51:50.821069",
     "exception": false,
     "start_time": "2022-04-25T01:51:50.793670",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Xavier initialization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b089b2b3",
   "metadata": {
    "papermill": {
     "duration": 0.034488,
     "end_time": "2022-04-25T01:51:50.883387",
     "exception": false,
     "start_time": "2022-04-25T01:51:50.848899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def weight_init_xavier_uniform(submodule):\n",
    "    if isinstance(submodule, torch.nn.Conv2d):\n",
    "        torch.nn.init.xavier_uniform_(submodule.weight)\n",
    "        # submodule.bias.data.fill_(0.01)\n",
    "\n",
    "# model.apply(weight_init_xavier_uniform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de0b648",
   "metadata": {
    "papermill": {
     "duration": 0.027122,
     "end_time": "2022-04-25T01:51:50.938266",
     "exception": false,
     "start_time": "2022-04-25T01:51:50.911144",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b45b5d27",
   "metadata": {
    "papermill": {
     "duration": 0.034868,
     "end_time": "2022-04-25T01:51:51.000715",
     "exception": false,
     "start_time": "2022-04-25T01:51:50.965847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_MSE_from_moduleList(moduleList):\n",
    "    device = \"cuda\" if cuda.is_available() else \"cpu\"\n",
    "    w = torch.tensor(0, dtype=torch.get_default_dtype()).to(device)\n",
    "    cnt = 0\n",
    "    for layer in moduleList:\n",
    "        for params in layer.parameters():\n",
    "            w.add_(torch.mean(torch.square(params)))\n",
    "            cnt += params.nelement()\n",
    "    return w / cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ca24245",
   "metadata": {
    "papermill": {
     "duration": 0.035918,
     "end_time": "2022-04-25T01:51:51.064309",
     "exception": false,
     "start_time": "2022-04-25T01:51:51.028391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_loss(model, coefficients, c, p, e_out, d_out):\n",
    "    \"\"\"get_loss function\n",
    "\n",
    "    Args:\n",
    "        model (model): EDS model\n",
    "        criterion (criterion): MSELoss\n",
    "        coefficients (dict): {alpha, beta, lambd}\n",
    "        c (B 3 W H): cover image batch\n",
    "        p (B 1 W H): payload image batch\n",
    "        e_out (B 3 W H): encoded(stego) image batch\n",
    "        d_out (B 1 W H): decoded image batch\n",
    "\n",
    "    Returns:\n",
    "        loss\n",
    "    \"\"\"\n",
    "    e_loss = nn.MSELoss()(c, e_out)\n",
    "    d_loss = nn.MSELoss()(p, d_out)\n",
    "    w_d = get_MSE_from_moduleList(model.decoder)\n",
    "    w_h = get_MSE_from_moduleList(model.host_branch)\n",
    "    w_g = get_MSE_from_moduleList(model.guest_branch)\n",
    "    w_loss = (w_h + w_g) / 2 + w_d\n",
    "\n",
    "    loss = (\n",
    "        coefficients[\"alpha\"] * e_loss\n",
    "        + coefficients[\"beta\"] * d_loss\n",
    "        + coefficients[\"lambd\"] * w_loss\n",
    "    )\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b15dc0be",
   "metadata": {
    "papermill": {
     "duration": 0.035177,
     "end_time": "2022-04-25T01:51:51.127204",
     "exception": false,
     "start_time": "2022-04-25T01:51:51.092027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_weight(\n",
    "    model, path, weight_file_name, loss_file_name, train_losses\n",
    "):\n",
    "        def make_path(path):\n",
    "            try:\n",
    "                os.makedirs(path)\n",
    "            except OSError:\n",
    "                if not os.path.isdir(path):\n",
    "                    raise\n",
    "            return path\n",
    "\n",
    "        path = make_path(path)\n",
    "\n",
    "        print(f\"[+] Saving {path}/{weight_file_name}\")\n",
    "        torch.save(model.state_dict(), f\"{path}/{weight_file_name}\")\n",
    "        with open(f\"{path}/{loss_file_name}\", \"w+\") as f:\n",
    "            for loss in train_losses:\n",
    "                f.write(\"%s\\n\" % loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d54551f1",
   "metadata": {
    "papermill": {
     "duration": 0.039802,
     "end_time": "2022-04-25T01:51:51.194815",
     "exception": false,
     "start_time": "2022-04-25T01:51:51.155013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_save(\n",
    "    model,\n",
    "    optimizer,\n",
    "    train_c_loader,\n",
    "    train_p_loader,\n",
    "    epochs,\n",
    "    period,\n",
    "    coefficients,\n",
    "    weight_path,\n",
    "):\n",
    "    model.train()\n",
    "    device = \"cuda\" if cuda.is_available() else \"cpu\"\n",
    "    train_losses = []\n",
    "    batchs = min(len(train_c_loader), len(train_p_loader))\n",
    "    \n",
    "    for epoch in trange(1, epochs+1, desc=\"Total\"):\n",
    "    # for epoch in range(1, epochs+1):\n",
    "        train_loss = 0.0\n",
    "        iter_c = iter(train_c_loader)\n",
    "        iter_p = iter(train_p_loader)\n",
    "        # pbar = tqdm(range(batchs), desc=f\"Epoch {epoch}/{epochs}\", ascii=True, leave=False)\n",
    "        pbar = range(batchs)\n",
    "        for i in pbar:\n",
    "            c = next(iter_c)[0].to(device)\n",
    "            p = next(iter_p)[0].to(device)\n",
    "            p = transforms.functional.rgb_to_grayscale(p) # (B, 1, H, W) # to_pil_image했을 때 제대로 나오는거 확인 O\n",
    "            \n",
    "            ### train step\n",
    "            optimizer.zero_grad()\n",
    "            e_out, d_out = model.forward(c, p)\n",
    "            loss = get_loss(model, coefficients, c, p, e_out, d_out)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_losses.append(train_loss / batchs)\n",
    "        # print(f\"[+] Train loss({epoch}/{epochs}): {train_losses[-1]}\")\n",
    "        # checkpoint\n",
    "        if epoch % period == 0 and len(weight_path) and epoch:\n",
    "            save_weight(\n",
    "                model,\n",
    "                weight_path,\n",
    "                f\"{epoch}.pickle\",\n",
    "                f\"{epoch}.txt\",\n",
    "                train_losses,\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9142ec2a",
   "metadata": {
    "papermill": {
     "duration": 0.027878,
     "end_time": "2022-04-25T01:51:51.249983",
     "exception": false,
     "start_time": "2022-04-25T01:51:51.222105",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Test (Infer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70dcfac2",
   "metadata": {
    "papermill": {
     "duration": 0.034645,
     "end_time": "2022-04-25T01:51:51.312690",
     "exception": false,
     "start_time": "2022-04-25T01:51:51.278045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_pil_image(pil_image, path, name):\n",
    "    \"\"\"save_pil_image\n",
    "\n",
    "    Args:\n",
    "        pil_image\n",
    "    \"\"\"\n",
    "    def make_path(path):\n",
    "        try:\n",
    "            os.makedirs(path)\n",
    "        except OSError:\n",
    "            if not os.path.isdir(path):\n",
    "                raise\n",
    "        return path\n",
    "    pil_image.save(f\"{make_path(path)}/{name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "167ddd4c",
   "metadata": {
    "papermill": {
     "duration": 0.03839,
     "end_time": "2022-04-25T01:51:51.378124",
     "exception": false,
     "start_time": "2022-04-25T01:51:51.339734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_merged_pil_image(pil_imgs, path, name):\n",
    "    \"\"\"save_merged_image\n",
    "\n",
    "    Args:\n",
    "        pil_imgs : [c_img, p_img, e_o_img, d_o_img]\n",
    "    \"\"\"\n",
    "    [c, p, e_o, d_o] = pil_imgs\n",
    "\n",
    "    plt.figure(tight_layout=True)\n",
    "    fontsize=15\n",
    "    plt.subplot(1, 4, 1)\n",
    "    # plt.subplot(2, 2, 1)\n",
    "    # plt.title(\"Cover\", fontsize=fontsize)\n",
    "    plt.imshow(c)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 4, 2)\n",
    "    # plt.subplot(2, 2, 2)\n",
    "    # plt.title(\"Encoded\", fontsize=fontsize)\n",
    "    plt.imshow(e_o)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 4, 3)\n",
    "    # plt.subplot(2, 2, 3)\n",
    "    # plt.title(\"Payload\", fontsize=fontsize)\n",
    "    plt.imshow(p, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 4, 4)\n",
    "    # plt.subplot(2, 2, 4)\n",
    "    # plt.title(\"Decoded\", fontsize=fontsize)\n",
    "    plt.imshow(d_o, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    def make_path(path):\n",
    "        try:\n",
    "            os.makedirs(path)\n",
    "        except OSError:\n",
    "            if not os.path.isdir(path):\n",
    "                raise\n",
    "        return path\n",
    "\n",
    "    plt.savefig(f\"{make_path(path)}/{name}\", transparent=True, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close('all') # prevent plt memory leak\n",
    "    plt.clf() # prevent plt memory leak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6c13a91",
   "metadata": {
    "papermill": {
     "duration": 0.045823,
     "end_time": "2022-04-25T01:51:51.451164",
     "exception": false,
     "start_time": "2022-04-25T01:51:51.405341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def infer_from_saved_weight(\n",
    "    model, test_c_loader, test_p_loader, weight_file, result_path\n",
    "):\n",
    "    device = \"cuda\" if cuda.is_available() else \"cpu\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.load_state_dict(torch.load(weight_file, map_location=device))\n",
    "        model.eval()\n",
    "\n",
    "        batchs = min(len(test_c_loader), len(test_p_loader))\n",
    "        len_datas = min(len(test_c_loader.dataset), len(test_p_loader.dataset))\n",
    "\n",
    "        iter_c = iter(test_c_loader)\n",
    "        iter_p = iter(test_p_loader)\n",
    "        total_e_psnr = 0.0\n",
    "        total_d_psnr = 0.0\n",
    "        total_e_ssim = 0.0\n",
    "        total_d_ssim = 0.0\n",
    "        total_e=0\n",
    "        total_d=0\n",
    "        for batch in trange(batchs, desc=\"Total\"):\n",
    "        # for batch in range(batchs):\n",
    "            e_psnr = 0.0\n",
    "            e_cnt=0\n",
    "            d_psnr = 0.0\n",
    "            d_cnt=0\n",
    "            e_ssim = 0.0\n",
    "            d_ssim = 0.0\n",
    "            c = next(iter_c)[0].to(device)\n",
    "            p = next(iter_p)[0].to(device)\n",
    "            p = transforms.functional.rgb_to_grayscale(p) # to_pil_image했을 때 제대로 나오는거 확인 O\n",
    "            e_o, d_o = model(c, p) # infer\n",
    "            # pbar = tqdm(range(batch_size), desc=f\"Batch {batch}/{batchs}\", ascii=True, leave=False)\n",
    "            pbar = range(batch_size)\n",
    "            for i in pbar:\n",
    "                # c_img = to_pil_image(c[i])\n",
    "                # p_img = to_pil_image(p[i])\n",
    "                # e_o_img = to_pil_image(e_o[i])\n",
    "                # d_o_img = to_pil_image(d_o[i])\n",
    "                # c_np = np.array(c_img) # [0, 255]\n",
    "                # p_np = np.array(p_img) # [0, 255]\n",
    "                # e_o_np = np.array(e_o_img) # [0, 255]\n",
    "                # d_o_np = np.array(d_o_img) # [0, 255]\n",
    "                c_np = c[i].mul(255).add_(0.5).clamp_(0, 255).permute(1, 2, 0).to(\"cpu\", torch.uint8).numpy()\n",
    "                p_np = p[i].mul(255).add_(0.5).clamp_(0, 255).permute(1, 2, 0).to(\"cpu\", torch.uint8).numpy().squeeze()\n",
    "                e_o_np = e_o[i].mul(255).add_(0.5).clamp_(0, 255).permute(1, 2, 0).to(\"cpu\", torch.uint8).numpy()\n",
    "                d_o_np = d_o[i].mul(255).add_(0.5).clamp_(0, 255).permute(1, 2, 0).to(\"cpu\", torch.uint8).numpy().squeeze()\n",
    "                c_img = Image.fromarray(c_np)\n",
    "                p_img = Image.fromarray(p_np)\n",
    "                e_o_img = Image.fromarray(e_o_np)\n",
    "                d_o_img = Image.fromarray(d_o_np)\n",
    "                # save result images\n",
    "                save_merged_pil_image(\n",
    "                    [c_img, p_img, e_o_img, d_o_img], f\"{result_path}/merged\", f\"{batch}-{i}.png\"\n",
    "                ) ## merged image\n",
    "                ## c, p, e_o, d_o separately\n",
    "                # save_pil_image(c_img, f\"{result_path}/c\", f\"{batch}-{i}.png\")\n",
    "                # save_pil_image(p_img, f\"{result_path}/p\", f\"{batch}-{i}.png\")\n",
    "                # save_pil_image(d_o_img, f\"{result_path}/d_o\", f\"{batch}-{i}.png\")\n",
    "                save_pil_image(e_o_img, f\"{result_path}/e_o\", f\"{batch}-{i}.png\") # encoded cover (stego) image\n",
    "                \n",
    "                # calc psnr, ssim\n",
    "                psnr=skimage.metrics.peak_signal_noise_ratio(c_np, e_o_np)\n",
    "                if psnr!=np.inf:\n",
    "                    e_psnr+=psnr\n",
    "                    e_cnt+=1\n",
    "                psnr=skimage.metrics.peak_signal_noise_ratio(p_np, d_o_np)\n",
    "                if psnr!=np.inf:\n",
    "                    d_psnr+=psnr\n",
    "                    d_cnt+=1\n",
    "                e_ssim += skimage.metrics.structural_similarity(\n",
    "                    c_np, e_o_np, multichannel=True, channel_axis=2 # channel 3개로 나눠서 계산한 평균과 같은 값이 나옴\n",
    "                )\n",
    "                d_ssim += skimage.metrics.structural_similarity(p_np, d_o_np)\n",
    "                # del c_img, p_img, e_o_img, d_o_img, c_np, p_np, e_o_np, d_o_np # not have to do\n",
    "            total_e+=e_cnt\n",
    "            total_d+=d_cnt\n",
    "            # save psnr, ssim\n",
    "            with open(f\"{result_path}/metrics-per-batch.txt\", \"a+\") as f:\n",
    "                f.write(f\"# {batch}\\n\")\n",
    "                f.write(f\"e_psnr: {e_psnr/e_cnt}\\n\")\n",
    "                f.write(f\"d_psnr: {d_psnr/d_cnt}\\n\")\n",
    "                f.write(f\"e_ssim: {e_ssim/batch_size}\\n\")\n",
    "                f.write(f\"d_ssim: {d_ssim/batch_size}\\n\")\n",
    "            total_e_psnr += e_psnr\n",
    "            total_d_psnr += d_psnr\n",
    "            total_e_ssim += e_ssim\n",
    "            total_d_ssim += d_ssim\n",
    "            # del c, p, e_o, d_o # not have to do\n",
    "        with open(result_path + \"/metrics-total.txt\", \"w+\") as f:\n",
    "            f.write(f\"total_e_psnr: {total_e_psnr/total_e}\\n\")\n",
    "            f.write(f\"total_d_psnr: {total_d_psnr/total_d}\\n\")\n",
    "            f.write(f\"total_e_ssim: {total_e_ssim/len_datas}\\n\")\n",
    "            f.write(f\"total_d_ssim: {total_d_ssim/len_datas}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947cbcef",
   "metadata": {
    "papermill": {
     "duration": 0.026976,
     "end_time": "2022-04-25T01:51:51.505223",
     "exception": false,
     "start_time": "2022-04-25T01:51:51.478247",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ae7e85",
   "metadata": {
    "papermill": {
     "duration": 0.026954,
     "end_time": "2022-04-25T01:51:51.559677",
     "exception": false,
     "start_time": "2022-04-25T01:51:51.532723",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Tree\n",
    "- weight/{model.name}/{train_set}/{epoch}.pickle\n",
    "    - cifar10\n",
    "        - 50.pickle\n",
    "        - 100.pickle\n",
    "        - 150.pickle\n",
    "    - celeba\n",
    "        - 50.pickle\n",
    "        - 100.pickle\n",
    "        - 150.pickle\n",
    "    - imagenet\n",
    "        - 50.pickle\n",
    "        - 100.pickle\n",
    "        - 150.pickle\n",
    "- result/{model.name}/{train_set}/{test_set}/{epoch}/{[c, p, d_o, e_d]}/*.png\n",
    "    - cifar10\n",
    "        - cifar10\n",
    "            - 150\n",
    "                - c\n",
    "                - p\n",
    "                - e_o\n",
    "                - d_o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ceedf4",
   "metadata": {
    "papermill": {
     "duration": 0.027174,
     "end_time": "2022-04-25T01:51:51.614164",
     "exception": false,
     "start_time": "2022-04-25T01:51:51.586990",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Global variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e87a8aa",
   "metadata": {
    "papermill": {
     "duration": 0.086978,
     "end_time": "2022-04-25T01:51:51.728449",
     "exception": false,
     "start_time": "2022-04-25T01:51:51.641471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 150  #!!!\n",
    "period = 50\n",
    "lr = 1e-4\n",
    "coefficients = {\n",
    "    \"alpha\": 1,\n",
    "    \"beta\": 1,\n",
    "    \"lambd\": 1e-4,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dbc205",
   "metadata": {
    "papermill": {
     "duration": 0.029932,
     "end_time": "2022-04-25T01:51:51.789246",
     "exception": false,
     "start_time": "2022-04-25T01:51:51.759314",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train function (CIFAR10, CelebA, ImageNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "268698df",
   "metadata": {
    "papermill": {
     "duration": 0.03714,
     "end_time": "2022-04-25T01:51:51.853841",
     "exception": false,
     "start_time": "2022-04-25T01:51:51.816701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(train_set):\n",
    "    global epochs, period, coefficients, lr, batch_size, device\n",
    "    \n",
    "    # train loader\n",
    "    if train_set=='cifar10':\n",
    "        train_c_loader, train_p_loader = build_cifar10_dataloader(batch_size)[:2]\n",
    "    elif train_set=='celeba':\n",
    "        train_c_loader, train_p_loader = build_celeba_dataloader(batch_size)[:2]\n",
    "    elif train_set=='imagenet':\n",
    "        train_c_loader, train_p_loader = build_imagenet_dataloader(batch_size)[:2]\n",
    "    else:\n",
    "        print(\"[-] invalid train_set\")\n",
    "        return\n",
    "    \n",
    "    model = EDS().to(device) ###############\n",
    "    model.apply(weight_init_xavier_uniform)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    weight_path = f\"./weight/{model.name}/{train_set}\"\n",
    "    \n",
    "    train_and_save(\n",
    "        model,\n",
    "        optimizer,\n",
    "        train_c_loader,\n",
    "        train_p_loader,\n",
    "        epochs,\n",
    "        period,\n",
    "        coefficients,\n",
    "        weight_path,\n",
    "    )\n",
    "    del train_c_loader, train_p_loader, model\n",
    "    print(f\"[+] train {train_set} done (epochs: {epochs})\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ba8d17",
   "metadata": {
    "papermill": {
     "duration": 0.027978,
     "end_time": "2022-04-25T01:51:51.909381",
     "exception": false,
     "start_time": "2022-04-25T01:51:51.881403",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Infer function (CIFAR10, CelebA, ImageNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "026b65c6",
   "metadata": {
    "papermill": {
     "duration": 0.036946,
     "end_time": "2022-04-25T01:51:51.974382",
     "exception": false,
     "start_time": "2022-04-25T01:51:51.937436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def infer(train_set, infer_set):\n",
    "    global epochs, period, coefficients, lr, batch_size, device\n",
    "    \n",
    "    # test loader\n",
    "    if infer_set=='cifar10':\n",
    "        test_c_loader, test_p_loader = build_cifar10_dataloader(batch_size)[2:]\n",
    "    elif infer_set=='celeba':\n",
    "        test_c_loader, test_p_loader = build_celeba_dataloader(batch_size)[2:]\n",
    "    elif infer_set=='imagenet':\n",
    "        test_c_loader, test_p_loader = build_imagenet_dataloader(batch_size)[2:]\n",
    "    else:\n",
    "        print(\"[-] invalid test_set\")\n",
    "        return\n",
    "    \n",
    "    model = EDS().to(device) ###############\n",
    "    weight_path = f\"./weight/{model.name}/{train_set}\"\n",
    "    for e in range(period, epochs+1, period):\n",
    "        result_path = f\"./result/{model.name}/{train_set}/{infer_set}/{e}\"\n",
    "        infer_from_saved_weight(model,\n",
    "                                test_c_loader,\n",
    "                                test_p_loader,\n",
    "                                f\"{weight_path}/{e}.pickle\",\n",
    "                                result_path)\n",
    "        shutil.make_archive(f\"{model.name}-{train_set}-{infer_set}-{e}\", \"zip\", result_path)\n",
    "        print(f\"[+] infer {infer_set} with {model.name}-{train_set} (epochs: {e}) done\")\n",
    "    del test_c_loader, test_p_loader, model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38bdded4",
   "metadata": {
    "papermill": {
     "duration": 0.034729,
     "end_time": "2022-04-25T01:51:52.036415",
     "exception": false,
     "start_time": "2022-04-25T01:51:52.001686",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_infer():\n",
    "    datasets=['cifar10', 'celeba', 'imagenet']\n",
    "    for train_set in datasets:\n",
    "        train(train_set)\n",
    "    for train_set in datasets:\n",
    "        # train(train_set)\n",
    "        for infer_set in datasets:\n",
    "            infer(train_set, infer_set)\n",
    "    print(\"[+] weight saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f44d169",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2022-04-25T01:51:52.063797",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Device: cuda\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[+] load cifar10: train_size = 40000, test_size = 20000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cdaa6330ee64ae48bf1f79eb2cc9e3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total:   0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Saving ./weight/EDS/cifar10/50.pickle\n",
      "[+] Saving ./weight/EDS/cifar10/100.pickle\n",
      "[+] Saving ./weight/EDS/cifar10/150.pickle\n",
      "[+] train cifar10 done (epochs: 150)\n",
      "[+] load celeba: train_size = 40000, test_size = 20000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09c831065cd441f6a970a63f0e4fd12b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total:   0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Saving ./weight/EDS/celeba/50.pickle\n",
      "[+] Saving ./weight/EDS/celeba/100.pickle\n",
      "[+] Saving ./weight/EDS/celeba/150.pickle\n",
      "[+] train celeba done (epochs: 150)\n",
      "[+] load imagenet: train_size = 40000, test_size = 20000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f40a59dbcc34c5789e546972e31d96b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total:   0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Saving ./weight/EDS/imagenet/50.pickle\n",
      "[+] Saving ./weight/EDS/imagenet/100.pickle\n",
      "[+] Saving ./weight/EDS/imagenet/150.pickle\n",
      "[+] train imagenet done (epochs: 150)\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[+] load cifar10: train_size = 40000, test_size = 20000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5adba16d3cf49c596621b4ce61a57e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total:   0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] infer cifar10 with EDS-cifar10 (epochs: 50) done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7598b44d1a484c72b11d98c1ba6523d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total:   0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] infer cifar10 with EDS-cifar10 (epochs: 100) done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c90574ee3e314902aa05397f249bedbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total:   0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] infer cifar10 with EDS-cifar10 (epochs: 150) done\n",
      "[+] load celeba: train_size = 40000, test_size = 20000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfa372d1704b490bb502af051bcaefa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total:   0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] infer celeba with EDS-cifar10 (epochs: 50) done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a56bf472db894f8e918e507baf6dae0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total:   0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] infer celeba with EDS-cifar10 (epochs: 100) done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04d2eeaeb28e4e2592243a508b8cbb47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total:   0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] infer celeba with EDS-cifar10 (epochs: 150) done\n",
      "[+] load imagenet: train_size = 40000, test_size = 20000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeff1512afca4a79bca74a440d3bc661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total:   0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] infer imagenet with EDS-cifar10 (epochs: 50) done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e90c2e443a704098aa8648a3e0a45bcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total:   0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] infer imagenet with EDS-cifar10 (epochs: 100) done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ccf572aba8447eeb543f07f4e160d72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total:   0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] infer imagenet with EDS-cifar10 (epochs: 150) done\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[+] load cifar10: train_size = 40000, test_size = 20000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b8ad5f8eea440d922d11f52a58f528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total:   0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] infer cifar10 with EDS-celeba (epochs: 50) done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55171d6336ce49918f8b7652f07789b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total:   0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] infer cifar10 with EDS-celeba (epochs: 100) done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e1896280bbc4c36a02f15dd492270b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total:   0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] infer cifar10 with EDS-celeba (epochs: 150) done\n",
      "[+] load celeba: train_size = 40000, test_size = 20000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e01889820ab4e38b324d19394c6e3dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total:   0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] infer celeba with EDS-celeba (epochs: 50) done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fc9b7c1003a402e8afefd8ca977ab34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total:   0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] infer celeba with EDS-celeba (epochs: 100) done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f2b218ac0e746629e64fde623be0b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total:   0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] infer celeba with EDS-celeba (epochs: 150) done\n",
      "[+] load imagenet: train_size = 40000, test_size = 20000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc72e643bba743b9b49441a75e65db08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total:   0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] infer imagenet with EDS-celeba (epochs: 50) done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ace28529b8ba4ccc954a30da30b49ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total:   0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] infer imagenet with EDS-celeba (epochs: 100) done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b06b6888bc7c421793f0f715b388f56a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total:   0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] infer imagenet with EDS-celeba (epochs: 150) done\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[+] load cifar10: train_size = 40000, test_size = 20000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b3dd99305414d648b7bbf6ef4785448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total:   0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] infer cifar10 with EDS-imagenet (epochs: 50) done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8a3a94f5ef1438e8434ff097e4192e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total:   0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] infer cifar10 with EDS-imagenet (epochs: 100) done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0833b1a945e742d8a8dbd820f97401cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total:   0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] infer cifar10 with EDS-imagenet (epochs: 150) done\n",
      "[+] load celeba: train_size = 40000, test_size = 20000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eef3d45e088a474da825ee2b0c6b8437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total:   0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] infer celeba with EDS-imagenet (epochs: 50) done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51c3abb562e940f590e6c79e4f949e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total:   0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] infer celeba with EDS-imagenet (epochs: 100) done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d9c58ac0db4ba882fc78e773418fb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total:   0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] infer celeba with EDS-imagenet (epochs: 150) done\n",
      "[+] load imagenet: train_size = 40000, test_size = 20000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f50bf7b685124949a49cdc7816e6e065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total:   0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] infer imagenet with EDS-imagenet (epochs: 50) done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f24de596937d474180f1318d72e44ca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total:   0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] infer imagenet with EDS-imagenet (epochs: 100) done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1240174c30a47be9f10540b0cb5dd33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total:   0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] infer imagenet with EDS-imagenet (epochs: 150) done\n",
      "[+] weight saved\n",
      "[+] done\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if cuda.is_available() else \"cpu\"\n",
    "print(\"[+] Device:\", device)\n",
    "\n",
    "train_and_infer()\n",
    "print('[+] done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-jhyun",
   "language": "python",
   "name": "pytorch-jhyun"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-25T01:51:28.844418",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
